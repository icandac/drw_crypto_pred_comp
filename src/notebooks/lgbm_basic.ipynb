{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faf7a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc, os, psutil\n",
    "from typing import List, Tuple\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from joblib import dump\n",
    "import warnings\n",
    "from src.utils.light_preprocess import Preprocessor\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "output_folder = '../../outputs/'\n",
    "seed = 42\n",
    "n_splits = 5\n",
    "\n",
    "def mem_mb() -> float:\n",
    "    \"\"\"Return current RSS in megabytes.\"\"\"\n",
    "    return psutil.Process(os.getpid()).memory_info().rss / 1e6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748f7db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_raw = pd.read_parquet('../../data/train.parquet')\n",
    "df_test_raw = pd.read_parquet('../../data/test.parquet')\n",
    "%store df_train_raw\n",
    "%store df_test_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af2acd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_filter(\n",
    "    df: pd.DataFrame, target_col: str = \"label\", thresh_ratio: float = 0.1\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove feature columns whose variance is < `thresh_ratio` x var(label).\n",
    "\n",
    "    Args:\n",
    "        df : DataFrame\n",
    "            Training frame (label + features).\n",
    "        thresh_ratio : float\n",
    "            Keep features whose var >= thresh_ratio * var(label).\n",
    "\n",
    "    Returns:\n",
    "        DataFrame\n",
    "    \"\"\"\n",
    "    label_var = df[target_col].var()\n",
    "    thresh = label_var * thresh_ratio\n",
    "\n",
    "    keep_cols = [target_col] + [\n",
    "        c for c in df.columns if c != target_col and df[c].var() >= thresh\n",
    "    ]\n",
    "    pruned = df[keep_cols].copy()\n",
    "    print(f\"Variance filter kept {len(keep_cols)-1} of {df.shape[1]-1} columns\")\n",
    "    return pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a178478",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = variance_filter(df_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df96138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_cluster_select(\n",
    "    df: pd.DataFrame, target: str = \"label\", thresh: float = 0.90\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Target-aware correlation-clustering filter.\n",
    "\n",
    "    Keeps at most **one** feature from every group of highly-correlated\n",
    "    columns (|corr| ≥ `thresh`).  For each group the survivor is the\n",
    "    feature with the strongest absolute correlation to the target.\n",
    "    Args:\n",
    "        df : DataFrame\n",
    "            Input frame that still contains `target`.\n",
    "        thresh : float\n",
    "            Absolute Pearson correlation threshold that triggers grouping\n",
    "            (default 0.90).\n",
    "    Returns:\n",
    "        DataFrame\n",
    "            Same rows, but with duplicates pruned.\n",
    "    \"\"\"\n",
    "    feats = df.drop(columns=[target])\n",
    "    y = df[target]\n",
    "\n",
    "    corr = feats.astype(\"float32\").corr().abs()\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool), k=1)\n",
    "    upper = corr.where(mask)\n",
    "\n",
    "    survivors: List[str] = []\n",
    "    processed = set()  # columns already clustered\n",
    "\n",
    "    for col in upper.columns:\n",
    "        if col in processed:\n",
    "            continue\n",
    "\n",
    "        # all features strongly correlated with `col`\n",
    "        cluster = upper.index[upper[col] >= thresh].tolist()\n",
    "        cluster.append(col)\n",
    "\n",
    "        processed.update(cluster)\n",
    "\n",
    "        # pick the column with largest |corr| to the label\n",
    "        best = feats[cluster].corrwith(y).abs().idxmax()\n",
    "        survivors.append(best)\n",
    "\n",
    "    # deduplicate while preserving order\n",
    "    survivors = list(dict.fromkeys(survivors))\n",
    "\n",
    "    kept_df = df[[target] + survivors].copy()\n",
    "    print(\n",
    "        f\"Correlation filter kept {len(survivors)} \"\n",
    "        f\"of {feats.shape[1]} columns (thresh={thresh})\"\n",
    "    )\n",
    "    return kept_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593e663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = corr_cluster_select(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfd9ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10f12c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_feature_importance(\n",
    "    df: pd.DataFrame,\n",
    "    target_col: str = \"label\",\n",
    "    n_splits: int = 5,\n",
    "    seed: int = 42,\n",
    "    importance_type: str = \"gain\",  # \"gain\" or \"split\",\n",
    "    var_ratio: float = 0.1,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Train LightGBM on each fold, average feature importances, and\n",
    "    return a ranked table.\n",
    "\n",
    "    Args:\n",
    "        df : DataFrame\n",
    "            Raw training frame (timestamp index, features + label).\n",
    "        target_col : str\n",
    "            Column name of the regression target.\n",
    "        n_splits : int\n",
    "            TimeSeriesSplit folds.\n",
    "        importance_type : str\n",
    "            \"gain\" - total gain of splits (default, more robust)\n",
    "            \"split\" - number of times the feature is used in splits.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with columns [feature, importance] sorted descending.\n",
    "    \"\"\"\n",
    "    y = df[target_col]\n",
    "    x = df.drop(columns=[target_col])\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    imp_accum = pd.Series(0.0, index=x.columns)\n",
    "\n",
    "    params = dict(\n",
    "        objective=\"regression\",\n",
    "        learning_rate=0.1,\n",
    "        num_leaves=256,\n",
    "        feature_fraction=0.9,\n",
    "        bagging_fraction=0.8,\n",
    "        bagging_freq=1,\n",
    "        seed=seed,\n",
    "        verbose=-1,\n",
    "    )\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(tscv.split(x), 1):\n",
    "        print(f\"Training fold {fold}/{n_splits} …\", end=\"\\r\")\n",
    "\n",
    "        x_tr = x.iloc[tr_idx].astype(\"float32\")\n",
    "        y_tr = y.iloc[tr_idx]\n",
    "        x_val = x.iloc[val_idx].astype(\"float32\")\n",
    "        y_val = y.iloc[val_idx]\n",
    "\n",
    "        tr_ds = lgb.Dataset(x_tr, y_tr, free_raw_data=False)\n",
    "        val_ds = lgb.Dataset(x_val, y_val, reference=tr_ds, free_raw_data=False)\n",
    "\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            tr_ds,\n",
    "            num_boost_round=1000,\n",
    "            valid_sets=[val_ds],\n",
    "            callbacks=[lgb.early_stopping(200)],\n",
    "        )\n",
    "\n",
    "        imp_accum += pd.Series(\n",
    "            model.feature_importance(importance_type=importance_type),\n",
    "            index=x.columns,\n",
    "            dtype=\"float64\",\n",
    "        )\n",
    "\n",
    "        del model, tr_ds, val_ds, x_tr, x_val  # <── release memory now\n",
    "        gc.collect()\n",
    "\n",
    "    imp_df = (\n",
    "        imp_accum.div(n_splits)\n",
    "        .sort_values(ascending=False)\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"feature\", 0: \"importance\"})\n",
    "    )\n",
    "\n",
    "    return imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "629643cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open this if variance and feature correlation are not used\n",
    "df_train = df_train_raw.copy()\n",
    "df_test = df_test_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8c8d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    }
   ],
   "source": [
    "# No need to run this if you already have the feature importance\n",
    "# from a previous run, just load it instead.\n",
    "# imp_df = pd.read_csv(f\"{output_folder}feature_importance.csv\")\n",
    "imp_df = compute_feature_importance(\n",
    "    df_train, target_col=\"label\", n_splits=5, var_ratio=0.1\n",
    ")\n",
    "imp_df.to_csv(f\"{output_folder}feature_importance.csv\", index=False)\n",
    "top_n = 48  # determined by optimize_topn_features with optuna method previously\n",
    "print(f\"Top {top_n} features:\\n\", imp_df.head(int(top_n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7262e5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_expand = imp_df.head(top_n)[\"feature\"].tolist()\n",
    "train_reduced = df_train[[\"label\", *cols_to_expand, \"volume\", \"sell_qty\", \"buy_qty\"]].copy()\n",
    "x_train = train_reduced.drop(columns=[\"label\"])\n",
    "y_train = df_train[\"label\"]\n",
    "%store train_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce40e1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre = Preprocessor(\n",
    "#         lag_steps=[1, 5, 30],\n",
    "#         rolling_windows=[5, 30, 60, 120, 720, 1440],\n",
    "#         clip_quantiles=(0.001, 0.999),\n",
    "#         expand_cols=cols_to_expand,\n",
    "#         aggregate=None,\n",
    "#     )\n",
    "\n",
    "# print(\"Fitting preprocessor …\")\n",
    "# train_feat = pre.fit_transform(train_reduced)\n",
    "# print(f\"After train preprocess: {mem_mb():,.0f} MB\")\n",
    "# y_train = train_feat[\"label\"]\n",
    "# x_train = train_feat.drop(columns=[\"label\"])\n",
    "# del train_feat, train_reduced\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e61e8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Transforming test …\")\n",
    "# test_reduced = df_test_raw[cols_to_expand].copy()\n",
    "# test = pre.transform(test_reduced)\n",
    "# print(f\"After test  preprocess: {mem_mb():,.0f} MB\")\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef58b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_pearson(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    r = np.corrcoef(labels, preds)[0, 1]          # fast 2-line Pearson\n",
    "    return 'pearson', r, True                     # True ⇒ higher is better\n",
    "\n",
    "\n",
    "def train_and_pick_best(x, y, n_splits=5):\n",
    "    \"\"\"\n",
    "    Train LightGBM models using Time Series Cross-Validation and pick the\n",
    "    best model based on Pearson correlation.\n",
    "    Args:\n",
    "        x (DataFrame): Feature DataFrame.\n",
    "        y (Series): Target variable.\n",
    "        n_splits (int): Number of splits for Time Series Cross-Validation.\n",
    "    Returns:\n",
    "        LightGBM model: The best model based on validation Pearson correlation.\n",
    "    \"\"\"\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    best_model = None\n",
    "    best_corr = -9\n",
    "    best_fold_id = None\n",
    "    best_iter = None\n",
    "\n",
    "    lgb_params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"None\",\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"num_leaves\": 256,\n",
    "        \"max_depth\": 1,\n",
    "        \"feature_fraction\": 0.9,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_freq\": 1,\n",
    "        \"drop_rate\": 0.15,\n",
    "        \"skip_drop\": 0.5,\n",
    "        \"max_drop\": 70,\n",
    "        \"uniform_drop\": True,\n",
    "        \"xgboost_dart_mode\": True,\n",
    "        \"seed\": seed,\n",
    "        \"verbose\": -1,\n",
    "        \"num_threads\": 4,\n",
    "    }\n",
    "\n",
    "    oof_pred = np.full(len(y), np.nan, dtype=np.float32)\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(tscv.split(x), 1):\n",
    "        x_tr = x.iloc[train_idx].astype(\"float32\")\n",
    "        x_val = x.iloc[val_idx].astype(\"float32\")\n",
    "        y_tr = y.iloc[train_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "\n",
    "        tr_ds = lgb.Dataset(x_tr, y_tr)\n",
    "        val_ds = lgb.Dataset(x_val, y_val, reference=tr_ds)\n",
    "\n",
    "        model = lgb.train(\n",
    "            lgb_params,\n",
    "            tr_ds,\n",
    "            num_boost_round=6000,\n",
    "            valid_sets=[val_ds],\n",
    "            feval=lgb_pearson,      # returns (\"pearson\", r, True)\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=500, first_metric_only=True),\n",
    "                lgb.log_evaluation(500),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        val_pred = model.predict(x_val, num_iteration=model.best_iteration)\n",
    "        oof_pred[val_idx] = val_pred\n",
    "        corr, _ = pearsonr(y_val, val_pred)\n",
    "        print(f\"Fold {fold}/{n_splits} - Pearson = {corr:.5f}\")\n",
    "\n",
    "        if corr > best_corr:\n",
    "            best_corr, best_model = corr, model\n",
    "            best_iter, best_fold_id = model.best_iteration, fold\n",
    "\n",
    "        del x_tr, y_tr, x_val, y_val, tr_ds, val_ds\n",
    "        gc.collect()\n",
    "\n",
    "    print(f\"Best fold: {best_fold_id}  (Pearson {best_corr:.5f}, \"\n",
    "          f\"best_iter {best_iter})\")\n",
    "    \n",
    "    mask = ~np.isnan(oof_pred)                   # safety (should be all True)\n",
    "    oof_corr = np.corrcoef(y.iloc[mask], oof_pred[mask])[0, 1]\n",
    "    print(f\"Out-of-fold Pearson = {oof_corr:.5f}\")\n",
    "\n",
    "    full_ds = lgb.Dataset(x.astype('float32'), y)\n",
    "    final_model = lgb.train(\n",
    "        lgb_params,\n",
    "        full_ds,\n",
    "        num_boost_round=best_iter,\n",
    "        feval=lgb_pearson,\n",
    "    )\n",
    "    \n",
    "    return final_model, best_iter, oof_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29992fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training model...\")\n",
    "model, best_iter, oof_corr = train_and_pick_best(x_train, y_train, n_splits=n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0978b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission(test_index, preds, out_path):\n",
    "    \"\"\"\n",
    "    Save predictions to a CSV file for submission.\n",
    "    Args:\n",
    "        test_index (Index): Index of the test dataset.\n",
    "        preds (np.ndarray): Predictions array.\n",
    "        out_path (str): Path to save the submission file.\n",
    "    \"\"\"\n",
    "    sub = pd.DataFrame({\"ID\": test_index, \"prediction\": preds})\n",
    "    sub = sub.sort_values(\"ID\")\n",
    "    sub.to_csv(out_path, index=False)\n",
    "    print(f\"Saved predictions to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3e2d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Making predictions...\")\n",
    "test = df_test_raw[cols_to_expand].copy()\n",
    "preds = model.predict(test, num_iteration=best_iter)\n",
    "\n",
    "save_submission(test.index, preds, out_path=f\"{output_folder}submission_lgbm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5894b6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"../../data/sample_submission.csv\")\n",
    "assert (sample.iloc[:, 0].values == test.index.values).all(), \\\n",
    "       \"💥  New test_feat index is NOT identical to sample IDs!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec800fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"label\" not in test_reduced.columns, \"💥  test file still holds labels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68504418",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_train_raw.index.is_monotonic_increasing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drw_crypto_pred_comp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
